{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('dl')"
  },
  "interpreter": {
   "hash": "753cf74a1b63db9003c1ef07366732ff5db983517e22597d3b51fe3bb51ca165"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys, os\n",
    "\n",
    "# Add utility_scripts in the current path so that they can be imported directly just like in interactive mode\n",
    "sys.path.append(os.path.abspath(\"../usr/lib/\"))\n",
    "for script_folder in os.listdir(\"../usr/lib/\"):\n",
    "    sys.path.append(os.path.abspath(\"../usr/lib/\"+script_folder))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from datetime import date\n",
    "from statistics import mean, median\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from lastquerytransformer import Riiid\n",
    "from riiidutils import RiiidDataset, riiid_collate_fn, riiid_collate_fn_right_padding"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "loc = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','Localhost')\n",
    "if loc == 'Interactive' or loc == 'Localhost':\n",
    "    conf = {\n",
    "        'train_size': 100_000,\n",
    "        'batch_size': 16,\n",
    "        # model\n",
    "        \"dropout\": 0.1,\n",
    "        # training loop\n",
    "        'epochs': 100,\n",
    "        'eval_steps': 3125,\n",
    "        # adam\n",
    "        'learning_rate': 1e-3,\n",
    "        'epsilon': 1e-8,\n",
    "        \"weight_decay\": 0.01,\n",
    "        # clip_grad_value\n",
    "        \"clip_value\": False\n",
    "    }\n",
    "# When it is run after an api push.\n",
    "elif loc == 'Batch':\n",
    "    conf = {\n",
    "        'train_size': 400_000,\n",
    "        'batch_size': 64,\n",
    "        # model\n",
    "        \"dropout\": 0.1,\n",
    "        # training loop\n",
    "        'epochs': 40,\n",
    "        'eval_steps': 3125,\n",
    "        # adam\n",
    "        'learning_rate': 1e-3,\n",
    "        'epsilon': 1e-8,\n",
    "        \"weight_decay\": 0.005,\n",
    "        # clip_grad_value\n",
    "        \"clip_value\": False\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "Le fichier train.csv comprend un peu plus de 100 millions de lignes.  \n",
    "Il y a un peu moins de 400 mille user_id uniques.  \n",
    "Le modèle utilisé dans ce notebook prend en entrée une série par utilisateur."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Features utilisées\n",
    "Pour chaque question de la série d'apprentissage d'un utilisateur quelconque  \n",
    "\n",
    "1. Question ID: correspond à content_id (lorsque l'élément est une question).\n",
    "2. Question part: correspond à part dans question.csv pour l'élément dont question_id correspondant à content_id\n",
    "3. Answer correctness: valeur de answered_correctly de l'exemple (ou target encoding de la question ?)\n",
    "4. Current question elapsed time: prior question de la question suivante.\n",
    "5. Timestamp difference: current question timestamp - timestamp of the last question from the same user"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chargement des données et instanciation des datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('../input/riiid-sequences/users_y.pickle', 'rb') as f:\n",
    "    users_y = pickle.load(f)\n",
    "with open('../input/riiid-sequences/users_cat.pickle', 'rb') as f:\n",
    "    users_cat = pickle.load(f)\n",
    "with open('../input/riiid-sequences/users_cont.pickle', 'rb') as f:\n",
    "    users_cont = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "seed = 12\n",
    "cat_train, cat_val, cont_train, cont_val, y_train, y_val = train_test_split(users_cat, users_cont, users_y, test_size=.05, random_state=seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "cat_train = cat_train[:conf['train_size']]\n",
    "cont_train = cont_train[:conf['train_size']]\n",
    "y_train = y_train[:conf['train_size']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "print(\"Number of train examples:\", len(y_train))\n",
    "print(\"Number of valid examples:\", len(y_val))\n",
    "print(\"Train set answered_correctly average value:\", \"{:.3}\".format(y_train.mean()))\n",
    "print(\"Valid set answered_correctly average value:\", \"{:.3}\".format(y_val.mean()))\n",
    "print(\"Train set median sequence length:\", \"{:.0f}\".format(median([user_seq.shape[0] for user_seq in cat_train])))\n",
    "print(\"Valid set median sequence length:\", \"{:.0f}\".format(median([user_seq.shape[0] for user_seq in cat_val])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train examples: 10000\n",
      "Number of valid examples: 19683\n",
      "Train set answered_correctly average value: 0.476\n",
      "Valid set answered_correctly average value: 0.475\n",
      "Train set median sequence length: 40\n",
      "Valid set median sequence length: 41\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batches\n",
    "Dynamic Padding: ajout de padding batch par batch pour avoir une même longueur de séquence dans chaque batch.  \n",
    "Uniform size batching: on trie les utilisateurs par longueur de séquence, afin d'avoir des longueurs plus proches dans chaque batch  \n",
    "\n",
    "Afin de mettre en œuvre ces deux stratégies on va par simplicité trier au préalable et conjointement les listes batch_cat, batch_cont et batch_y par longueur des séquences dans batch_cat/batch_cont (c'est RiiidDataset qui s'en charge). Le DataLoader utilisera une fonction collate_fn permettant d'ajouter du padding dynamiquement batch par batch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# train_dataset = RiiidDataset(cat_train, cont_train, y_train, sort_sequences=False)\n",
    "# val_dataset = RiiidDataset(cat_val, cont_val, y_val, sort_sequences=False)\n",
    "train_dataset = RiiidDataset(cat_train, cont_train, y_train, sort_sequences=True)\n",
    "val_dataset = RiiidDataset(cat_val, cont_val, y_val, sort_sequences=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn, drop_last=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4*conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn, pin_memory=True)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn_right_padding, drop_last=True, pin_memory=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4*conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn_right_padding, pin_memory=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without dynamic batching"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# cat_train = pad_sequence_left([torch.tensor(el) for el in cat_train], batch_first=True)\n",
    "# cont_train = pad_sequence_left([torch.tensor(el, dtype=torch.float) for el in cont_train], batch_first=True)\n",
    "# #y = torch.tensor(y, dtype=torch.float)\n",
    "# cat_val = pad_sequence_left([torch.tensor(el) for el in cat_val], batch_first=True)\n",
    "# cont_val = pad_sequence_left([torch.tensor(el, dtype=torch.float) for el in cont_val], batch_first=True)\n",
    "# #y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "# train_dataset = RiiidDataset(cat_train, cont_train, y_train, sort_sequences=False)\n",
    "# val_dataset = RiiidDataset(cat_val, cont_val, y_val, sort_sequences=False)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=False, drop_last=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4*conf['batch_size'], shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle\n",
    "Pour le modèle, l'auteur s'est inspiré de la solution arrivée 3è à la compétition data Science bowl 2019 ([discussion](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127891), [code](https://www.kaggle.com/limerobot/dsb2019-v77-tr-dt-aug0-5-3tta))  \n",
    "La procédure de création des embeddings est expliquée, on suppose que l'auteur s'est basé dessus.\n",
    "## Embeddings\n",
    "On utilise un embedding catégoriel pour les 3 premières variables et un embedding continu pour les 2 dernières."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "maximums = {'question_id': 13523, 'part': 7, 'answered_correctly': 3}\n",
    "model = Riiid(maximums, dropout=conf[\"dropout\"]).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=conf['learning_rate'], eps=conf['epsilon'], weight_decay=conf[\"weight_decay\"])\n",
    "# optimizer = optim.SGD(model.parameters(), lr=conf[\"learning_rate\"], momentum=0.9)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, \"min\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "completed_epochs = 0\n",
    "step = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# checkpoint = torch.load('../input/lastquerytransformer40ebundlefix/lqt-2021-07-25.pt')\n",
    "# completed_epochs = checkpoint['epoch']\n",
    "# step = checkpoint[\"step\"]\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# checkpoint[\"model_state_dict\"][\"emb.answer_emb.weight\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0285,  0.0210, -0.1024,  0.0199, -0.2615, -0.1201,  0.1142, -0.0103,\n",
       "          0.0225,  0.0202,  0.0202,  0.2814, -0.0219, -0.1434,  0.0209,  0.1923],\n",
       "        [-0.0690, -0.0488,  0.0263, -0.0451,  0.2369,  0.0832, -0.1004,  0.0188,\n",
       "         -0.0460, -0.0463, -0.0513, -0.2330,  0.0505,  0.1421, -0.0488, -0.1434],\n",
       "        [-0.0191, -0.0043,  0.5764, -0.0070,  0.0422,  0.1948,  0.0586,  0.0118,\n",
       "         -0.0062, -0.0063, -0.0050, -0.1501,  0.0043, -0.1194, -0.0031, -0.2201]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x_cat = batch['cat'].to(device)\n",
    "        x_cont = batch['cont'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        if \"lengths\" in batch:\n",
    "            seq_lengths = batch['lengths']\n",
    "        else:\n",
    "            seq_lengths = None\n",
    "        ypred = model(x_cat, x_cont, seq_lengths).squeeze(1)\n",
    "        loss = criterion(ypred, y)\n",
    "\n",
    "        losses.append(float(loss))\n",
    "        accuracies.append((torch.round(torch.sigmoid(ypred)) == y).float().mean().item())\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_score.extend(torch.sigmoid(ypred).cpu().numpy())\n",
    "\n",
    "    return mean(losses), mean(accuracies), roc_auc_score(y_true, y_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "print(evaluate(model, criterion, train_loader))\n",
    "print(evaluate(model, criterion, val_loader))\n",
    "# Time to run on laptop with 100k examples (train)\n",
    "# max_len=0, sort_sequences=True, shuffle=False: 58 s\n",
    "# max_len=0, sort_sequences=False, shuffle=True: 408 s"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0.732813031578064, 0.5238, 0.4787713652801327)\n",
      "(0.7328240097343147, 0.5249289773501359, 0.47413357435807724)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "log_dir = \"tensorboard\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "if log_dir is not None:\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "for e in range(completed_epochs, completed_epochs+conf['epochs']):\n",
    "    print(\"Epoch \", e)\n",
    "    for batch in train_loader:\n",
    "        #print(scaler.get_scale())\n",
    "        model.train()\n",
    "        x_cat = batch['cat'].to(device)\n",
    "        x_cont = batch['cont'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        if \"lengths\" in batch:\n",
    "            seq_lengths = batch['lengths']#.to(device)\n",
    "        else:\n",
    "            seq_lengths = None\n",
    "        with autocast(enabled=False):\n",
    "            ypred = model(x_cat, x_cont, seq_lengths).squeeze(1)\n",
    "            if ypred.isnan().sum() or ypred.isinf().sum():\n",
    "                print(\"Nan value in output!\")\n",
    "            loss = criterion(ypred, y)\n",
    "            if loss.isnan().sum() or loss.isinf().sum():\n",
    "                print(\"Nan value in loss!\")\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        #scaler.scale(loss).backward()\n",
    "        \n",
    "        # unscale to apply gradient clipping\n",
    "        #scaler.unscale_(optimizer)\n",
    "        if conf[\"clip_value\"]:\n",
    "            nn.utils.clip_grad_value_(model.parameters(), clip_value=conf[\"clip_value\"])\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        #scaler.step(optimizer)\n",
    "        #scaler.update()\n",
    "\n",
    "        step += 1\n",
    "        if step % conf['eval_steps'] == 0:\n",
    "            train_loss, train_acc, train_auc = evaluate(model, criterion, train_loader)\n",
    "            print(\"Step\", step, end=\"\\n\")\n",
    "            print(\"Train loss:\", \"{:.3f}\".format(train_loss), end=\" \")\n",
    "            print(\"Train accuracy:\", \"{:.3f}\".format(train_acc), end=' ')\n",
    "            print(\"Train AUC:\", \"{:.3f}\".format(train_auc), end='\\n')\n",
    "            if log_dir is not None:\n",
    "                writer.add_scalar(\"train/loss\", train_loss, step)\n",
    "                writer.add_scalar(\"train/accuracy\", train_acc, step)\n",
    "                writer.add_scalar(\"train/auc\", train_auc, step)\n",
    "            if val_loader is not None:\n",
    "                val_loss, val_acc, val_auc = evaluate(model, criterion, val_loader)\n",
    "                print(\"Valid loss:\", \"{:.3f}\".format(val_loss), end=\" \")\n",
    "                print(\"Valid accuracy:\", \"{:.3f}\".format(val_acc), end=\" \")\n",
    "                print(\"Valid AUC:\", \"{:.3f}\".format(val_auc), end='\\n')\n",
    "                if log_dir is not None:\n",
    "                    writer.add_scalar(\"eval/loss\", val_loss, step)\n",
    "                    writer.add_scalar(\"eval/acc\", val_acc, step)\n",
    "                    writer.add_scalar(\"eval/auc\", val_auc, step)\n",
    "                #scheduler.step(val_loss)\n",
    "\n",
    "if log_dir is not None:\n",
    "    writer.close()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0\n",
      "Epoch  1\n",
      "Epoch  2\n",
      "Epoch  3\n",
      "Epoch  4\n",
      "Step 3125\n",
      "Train loss: 0.647 Train accuracy: 0.620 Train AUC: 0.720\n",
      "Valid loss: 0.686 Valid accuracy: 0.580 Valid AUC: 0.649\n",
      "Epoch  5\n",
      "Epoch  6\n",
      "Epoch  7\n",
      "Epoch  8\n",
      "Epoch  9\n",
      "Step 6250\n",
      "Train loss: 0.576 Train accuracy: 0.695 Train AUC: 0.803\n",
      "Valid loss: 0.718 Valid accuracy: 0.580 Valid AUC: 0.627\n",
      "Epoch  10\n",
      "Epoch  11\n",
      "Epoch  12\n",
      "Epoch  13\n",
      "Epoch  14\n",
      "Step 9375\n",
      "Train loss: 0.434 Train accuracy: 0.808 Train AUC: 0.895\n",
      "Valid loss: 0.807 Valid accuracy: 0.593 Valid AUC: 0.627\n",
      "Epoch  15\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a59c280fe061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mseq_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nan value in output!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/pierre-si/riiid/usr/lib/lastquerytransformer/lastquerytransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_cat, x_cont, seq_lengths)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m#x = self.lstm(x)[0][-1] # output: S × N × hidden_size, thus N × hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (h_n, c_n)[0][0], h_n: n_layers*n_directions (=1) × N × hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;31m#x = x.transpose(1, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/dl/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "torch.save({\n",
    "            'epoch': e,\n",
    "            \"step\": step,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            }, \"lqt-\"+str(date.today())+\".pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Error analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# train_dataset[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[4887,    5,    3],\n",
       "        [4033,    5,    1],\n",
       "        [5928,    5,    1],\n",
       "        ...,\n",
       "        [9820,    5,    2],\n",
       "        [9507,    5,    1],\n",
       "        [8874,    5,    2]]),\n",
       " array([[249000.,      0.],\n",
       "        [ 18000.,  21186.],\n",
       "        [ 31000.,  33844.],\n",
       "        ...,\n",
       "        [ 44000.,  78052.],\n",
       "        [ 17000.,  68609.],\n",
       "        [     0., 213212.]]),\n",
       " 1,\n",
       " 17609)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# batch = next(iter(train_loader)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# x_cat = batch['cat'].to(device)\n",
    "# x_cont = batch['cont'].to(device)\n",
    "# y = batch['y'].to(device)\n",
    "# seq_lengths = batch['lengths']#.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "# x_cat_copy = x_cat.clone()\n",
    "# x_cont_copy = x_cont.clone()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "# x_cont_copy[0, -5:, 1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2.2320e+05, 5.0000e+01, 5.0000e+01, 5.0000e+01, 5.0000e+01],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "# x_cont_copy[0, -5, 1] = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "# model(x_cat_copy, x_cont_copy, seq_lengths)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.8957]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}