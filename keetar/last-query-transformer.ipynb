{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('dl': venv)"
  },
  "interpreter": {
   "hash": "753cf74a1b63db9003c1ef07366732ff5db983517e22597d3b51fe3bb51ca165"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add utility_scripts in the current path so that they can be imported directly just like in interactive mode\n",
    "sys.path.append(os.path.abspath(\"../usr/lib/\"))\n",
    "for script_folder in os.listdir(\"../usr/lib/\"):\n",
    "    sys.path.append(os.path.abspath(\"../usr/lib/\"+script_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from statistics import mean, median\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lastquerytransformer import Riiid\n",
    "from riiidutils import RiiidDataset, riiid_collate_fn, riiid_collate_fn_right_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','Localhost')\n",
    "if loc == 'Interactive' or loc == 'Localhost':\n",
    "    conf = {\n",
    "        'batch_size': 8,\n",
    "        'train_size': 40_000,\n",
    "        'epochs': 15,\n",
    "        'eval_steps': 500,\n",
    "        'learning_rate': 2e-4\n",
    "    }\n",
    "# When it is run after an api push.\n",
    "elif loc == 'Batch':\n",
    "    conf = {\n",
    "        'batch_size': 32,\n",
    "        'train_size': 400_000,\n",
    "        'epochs': 30,\n",
    "        'eval_steps': 2500,\n",
    "        'learning_rate': 4e-4\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "\n",
    "Le fichier train.csv comprend un peu plus de 100 millions de lignes.  \n",
    "Il y a un peu moins de 400 mille user_id uniques.  \n",
    "Le modèle utilisé dans ce notebook prend en entrée une série par utilisateur."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Features utilisées\n",
    "Pour chaque question de la série d'apprentissage d'un utilisateur quelconque  \n",
    "\n",
    "1. Question ID: correspond à content_id (lorsque l'élément est une question).\n",
    "2. Question part: correspond à part dans question.csv pour l'élément dont question_id correspondant à content_id\n",
    "3. Answer correctness: valeur de answered_correctly de l'exemple (ou target encoding de la question ?)\n",
    "4. Current question elapsed time: prior question de la question suivante.\n",
    "5. Timestamp difference: current question timestamp - timestamp of the last question from the same user"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Chargement des données et instanciation des datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/riiid-sequences/users_y.pickle', 'rb') as f:\n",
    "    users_y = pickle.load(f)\n",
    "with open('../input/riiid-sequences/users_cat.pickle', 'rb') as f:\n",
    "    users_cat = pickle.load(f)\n",
    "with open('../input/riiid-sequences/users_cont.pickle', 'rb') as f:\n",
    "    users_cont = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "cat_train, cat_val, cont_train, cont_val, y_train, y_val = train_test_split(users_cat, users_cont, users_y, test_size=.05, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = cat_train[:conf['train_size']]\n",
    "cont_train = cont_train[:conf['train_size']]\n",
    "y_train = y_train[:conf['train_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train examples: 40000\nNumber of valid examples: 19683\nTrain set answered_correctly average value: 0.469\nValid set answered_correctly average value: 0.475\nTrain set median sequence length: 40\nValid set median sequence length: 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train examples:\", len(y_train))\n",
    "print(\"Number of valid examples:\", len(y_val))\n",
    "print(\"Train set answered_correctly average value:\", \"{:.3}\".format(y_train.mean()))\n",
    "print(\"Valid set answered_correctly average value:\", \"{:.3}\".format(y_val.mean()))\n",
    "print(\"Train set median sequence length:\", \"{:.0f}\".format(median([user_seq.shape[0] for user_seq in cat_train])))\n",
    "print(\"Valid set median sequence length:\", \"{:.0f}\".format(median([user_seq.shape[0] for user_seq in cat_val])))"
   ]
  },
  {
   "source": [
    "## Batches\n",
    "Dynamic Padding: ajout de padding batch par batch pour avoir une même longueur de séquence dans chaque batch.  \n",
    "Uniform size batching: on trie les utilisateurs par longueur de séquence, afin d'avoir des longueurs plus proches dans chaque batch  \n",
    "\n",
    "Afin de mettre en œuvre ces deux stratégies on va par simplicité trier au préalable et conjointement les listes batch_cat, batch_cont et batch_y par longueur des séquences dans batch_cat/batch_cont (c'est RiiidDataset qui s'en charge). Le DataLoader utilisera une fonction collate_fn permettant d'ajouter du padding dynamiquement batch par batch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RiiidDataset(cat_train, cont_train, y_train, sort_sequences=True)\n",
    "val_dataset = RiiidDataset(cat_val, cont_val, y_val, sort_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn_right_padding, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4*conf['batch_size'], shuffle=False, collate_fn=riiid_collate_fn_right_padding)"
   ]
  },
  {
   "source": [
    "Without dynamic batching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_train = pad_sequence_left([torch.tensor(el) for el in cat_train], batch_first=True)\n",
    "# cont_train = pad_sequence_left([torch.tensor(el, dtype=torch.float) for el in cont_train], batch_first=True)\n",
    "# #y = torch.tensor(y, dtype=torch.float)\n",
    "# cat_val = pad_sequence_left([torch.tensor(el) for el in cat_val], batch_first=True)\n",
    "# cont_val = pad_sequence_left([torch.tensor(el, dtype=torch.float) for el in cont_val], batch_first=True)\n",
    "# #y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "# train_dataset = RiiidDataset(cat_train, cont_train, y_train, sort_sequences=False)\n",
    "# val_dataset = RiiidDataset(cat_val, cont_val, y_val, sort_sequences=False)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=False, drop_last=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4*conf['batch_size'], shuffle=False)"
   ]
  },
  {
   "source": [
    "# Modèle\n",
    "Pour le modèle, l'auteur s'est inspiré de la solution arrivée 3è à la compétition data Science bowl 2019 ([discussion](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127891), [code](https://www.kaggle.com/limerobot/dsb2019-v77-tr-dt-aug0-5-3tta))  \n",
    "La procédure de création des embeddings est expliquée, on suppose que l'auteur s'est basé dessus.\n",
    "## Embeddings\n",
    "On utilise un embedding catégoriel pour les 3 premières variables et un embedding continu pour les 2 dernières.\n",
    "Contrairement à la solution du lien ci-dessus on utilise un embedding catégoriel par variable catégorielle plutôt qu'un embedding commun, comme recommandé [ici](https://discuss.pytorch.org/t/categorical-embeddings-can-i-only-have-1-categorical-column-per-embedding-layer/104681/3)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximums = {'question_id': 13523, 'part': 7, 'answered_correctly': 3}\n",
    "model = Riiid(maximums, dropout=0).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=conf['learning_rate'])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "completed_epochs = 0"
   ]
  },
  {
   "source": [
    "## Loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('../input/lastquerytransformer40ebundlefix/lqt-2021-04-18.pt')\n",
    "# completed_epochs = checkpoint['epoch']\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            x_cat = batch['cat'].to(device)\n",
    "            x_cont = batch['cont'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            seq_lengths = batch['lengths']#.to(device)\n",
    "\n",
    "            ypred = model(x_cat, x_cont, seq_lengths).squeeze(1)\n",
    "            loss = criterion(ypred, y)\n",
    "\n",
    "            losses.append(float(loss))\n",
    "            accuracies.append((torch.round(torch.sigmoid(ypred)) == y).float().mean().item())\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_score.extend(torch.sigmoid(ypred).cpu().numpy())\n",
    "\n",
    "    return mean(losses), mean(accuracies), roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0.6956996984362602, 0.46925, 0.5595199986155723)\n",
      "(0.6953269601255269, 0.4745332792207792, 0.5573995389198056)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, criterion, train_loader))\n",
    "print(evaluate(model, criterion, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7cce9776342c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mseq_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/pierre-si/riiid/usr/lib/lastquerytransformer/lastquerytransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_cat, x_cont, seq_lengths)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pytorch MHA requires input to be S×N×E (S: source sequence length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m#x = self.lstm(x)[0][-1] # output: S × N × hidden_size, thus N × hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (h_n, c_n)[0][0], h_n: n_layers*n_directions (=1) × N × hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/dl/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor"
     ]
    }
   ],
   "source": [
    "if log_dir is not None:\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "step = 0\n",
    "for e in range(completed_epochs, completed_epochs+conf['epochs']):\n",
    "    print(\"Epoch \", e)\n",
    "    for batch in train_loader:\n",
    "        model.train()\n",
    "        x_cat = batch['cat'].to(device)\n",
    "        x_cont = batch['cont'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        seq_lengths = batch['lengths']#.to(device)\n",
    "\n",
    "        ypred = model(x_cat, x_cont, seq_lengths).squeeze(1)\n",
    "        loss = criterion(ypred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "        if step % conf['eval_steps'] == 0:\n",
    "            train_loss, train_acc, train_auc = evaluate(model, criterion, train_loader)\n",
    "            print(\"Step\", step, end=\"\\n\")\n",
    "            print(\"Train loss:\", \"{:.3f}\".format(train_loss), end=\" \")\n",
    "            print(\"Train accuracy:\", \"{:.3f}\".format(train_acc), end=' ')\n",
    "            print(\"Train AUC:\", \"{:.3f}\".format(train_auc), end='\\n')\n",
    "            if log_dir is not None:\n",
    "                writer.add_scalar(\"train/loss\", train_loss, step)\n",
    "                writer.add_scalar(\"train/accuracy\", train_acc, step)\n",
    "                writer.add_scalar(\"train/auc\", train_auc, step)\n",
    "            if val_loader is not None:\n",
    "                val_loss, val_acc, val_auc = evaluate(model, criterion, val_loader)\n",
    "                print(\"Valid loss:\", \"{:.3f}\".format(val_loss), end=\" \")\n",
    "                print(\"Valid accuracy:\", \"{:.3f}\".format(val_acc), end=\" \")\n",
    "                print(\"Valid AUC:\", \"{:.3f}\".format(val_auc), end='\\n')\n",
    "                if log_dir is not None:\n",
    "                    writer.add_scalar(\"eval/loss\", val_loss, step)\n",
    "                    writer.add_scalar(\"eval/acc\", val_acc, step)\n",
    "                    writer.add_scalar(\"eval/auc\", val_auc, step)\n",
    "\n",
    "if log_dir is not None:\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            }, \"lqt-\"+str(date.today())+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}